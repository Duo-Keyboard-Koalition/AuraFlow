{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20c09cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 18:38:49.900515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - ETA: 0s - loss: 5.9384 - accuracy: 0.6764"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 18:38:58.967711: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 10s 60ms/step - loss: 5.9384 - accuracy: 0.6764 - val_loss: 0.5065 - val_accuracy: 0.7770\n",
      "Epoch 2/30\n",
      "157/157 [==============================] - 8s 53ms/step - loss: 0.4213 - accuracy: 0.8193 - val_loss: 0.3731 - val_accuracy: 0.8515\n",
      "Epoch 3/30\n",
      "157/157 [==============================] - 9s 57ms/step - loss: 0.3112 - accuracy: 0.8827 - val_loss: 0.2401 - val_accuracy: 0.9125\n",
      "Epoch 4/30\n",
      "157/157 [==============================] - 9s 59ms/step - loss: 0.2280 - accuracy: 0.9129 - val_loss: 0.2133 - val_accuracy: 0.9275\n",
      "Epoch 5/30\n",
      "157/157 [==============================] - 8s 54ms/step - loss: 0.1758 - accuracy: 0.9294 - val_loss: 0.1755 - val_accuracy: 0.9340\n",
      "Epoch 6/30\n",
      "157/157 [==============================] - 9s 54ms/step - loss: 0.1410 - accuracy: 0.9419 - val_loss: 0.1889 - val_accuracy: 0.9335\n",
      "Epoch 7/30\n",
      "157/157 [==============================] - 8s 53ms/step - loss: 0.1257 - accuracy: 0.9479 - val_loss: 0.1633 - val_accuracy: 0.9420\n",
      "Epoch 8/30\n",
      "157/157 [==============================] - 8s 53ms/step - loss: 0.1129 - accuracy: 0.9527 - val_loss: 0.3273 - val_accuracy: 0.8840\n",
      "Epoch 9/30\n",
      "157/157 [==============================] - 8s 53ms/step - loss: 0.1099 - accuracy: 0.9581 - val_loss: 0.4431 - val_accuracy: 0.8435\n",
      "Epoch 10/30\n",
      "157/157 [==============================] - 8s 53ms/step - loss: 0.0976 - accuracy: 0.9583 - val_loss: 0.1659 - val_accuracy: 0.9380\n",
      "Epoch 11/30\n",
      "157/157 [==============================] - 9s 54ms/step - loss: 0.0887 - accuracy: 0.9625 - val_loss: 0.1672 - val_accuracy: 0.9385\n",
      "Epoch 12/30\n",
      "157/157 [==============================] - 8s 53ms/step - loss: 0.0599 - accuracy: 0.9738 - val_loss: 0.2040 - val_accuracy: 0.9445\n",
      "Epoch 13/30\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.0589 - accuracy: 0.9761 - val_loss: 0.1814 - val_accuracy: 0.9500\n",
      "Epoch 14/30\n",
      "157/157 [==============================] - 9s 55ms/step - loss: 0.0511 - accuracy: 0.9778 - val_loss: 0.2110 - val_accuracy: 0.9325\n",
      "Epoch 15/30\n",
      "157/157 [==============================] - 8s 54ms/step - loss: 0.0637 - accuracy: 0.9726 - val_loss: 0.2425 - val_accuracy: 0.9280\n",
      "Epoch 16/30\n",
      "157/157 [==============================] - 9s 54ms/step - loss: 0.0461 - accuracy: 0.9801 - val_loss: 0.3754 - val_accuracy: 0.8940\n",
      "Epoch 17/30\n",
      "157/157 [==============================] - 9s 59ms/step - loss: 0.0872 - accuracy: 0.9666 - val_loss: 0.2643 - val_accuracy: 0.9455\n",
      "Epoch 18/30\n",
      "157/157 [==============================] - 9s 57ms/step - loss: 0.0463 - accuracy: 0.9804 - val_loss: 0.2191 - val_accuracy: 0.9410\n",
      "Epoch 19/30\n",
      "157/157 [==============================] - 9s 57ms/step - loss: 0.0238 - accuracy: 0.9891 - val_loss: 0.2223 - val_accuracy: 0.9480\n",
      "Epoch 20/30\n",
      "157/157 [==============================] - 9s 57ms/step - loss: 0.0357 - accuracy: 0.9851 - val_loss: 0.2061 - val_accuracy: 0.9450\n",
      "Epoch 21/30\n",
      "157/157 [==============================] - 9s 57ms/step - loss: 0.0318 - accuracy: 0.9867 - val_loss: 0.2109 - val_accuracy: 0.9520\n",
      "Epoch 22/30\n",
      "157/157 [==============================] - 8s 54ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.2263 - val_accuracy: 0.9520\n",
      "Epoch 23/30\n",
      "157/157 [==============================] - 8s 53ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.2220 - val_accuracy: 0.9495\n",
      "Epoch 24/30\n",
      "157/157 [==============================] - 9s 57ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.2787 - val_accuracy: 0.9455\n",
      "Epoch 25/30\n",
      "157/157 [==============================] - 10s 61ms/step - loss: 0.0792 - accuracy: 0.9740 - val_loss: 0.2068 - val_accuracy: 0.9455\n",
      "Epoch 26/30\n",
      "157/157 [==============================] - 9s 54ms/step - loss: 0.0346 - accuracy: 0.9871 - val_loss: 0.1894 - val_accuracy: 0.9515\n",
      "Epoch 27/30\n",
      "157/157 [==============================] - 8s 54ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.2378 - val_accuracy: 0.9560\n",
      "Epoch 28/30\n",
      "157/157 [==============================] - 9s 54ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.2359 - val_accuracy: 0.9550\n",
      "Epoch 29/30\n",
      "157/157 [==============================] - 9s 55ms/step - loss: 0.0238 - accuracy: 0.9914 - val_loss: 0.3196 - val_accuracy: 0.9400\n",
      "Epoch 30/30\n",
      "157/157 [==============================] - 9s 57ms/step - loss: 0.0910 - accuracy: 0.9692 - val_loss: 0.2874 - val_accuracy: 0.9380\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
    "# Please note that the weight of the grade for the question is relative to its\n",
    "# difficulty. So your Category 1 question will score significantly less than\n",
    "# your Category 5 question.\n",
    "#\n",
    "# WARNING: Do not use lambda layers in your model, they are not supported\n",
    "# on the grading infrastructure. You do not need them to solve the question.\n",
    "#\n",
    "# You must use the Submit and Test button to submit your model\n",
    "# at least once in this category before you finally submit your exam,\n",
    "# otherwise you will score zero for this category.\n",
    "# ======================================================================\n",
    "#\n",
    "# COMPUTER VISION WITH CNNs\n",
    "#\n",
    "# Create and train a classifier to classify images between two classes\n",
    "# (damage and no_damage) using the satellite-images-of-hurricane-damage dataset.\n",
    "# ======================================================================\n",
    "#\n",
    "# ABOUT THE DATASET\n",
    "#\n",
    "# Original Source:\n",
    "# https://ieee-dataport.org/open-access/detecting-damaged-buildings-post-hurricane-satellite-imagery-based-customized\n",
    "# The dataset consists of satellite images from Texas after Hurricane Harvey\n",
    "# divided into two groups (damage and no_damage).\n",
    "# ==============================================================================\n",
    "#\n",
    "# INSTRUCTIONS\n",
    "#\n",
    "# We have already divided the data for training and validation.\n",
    "#\n",
    "# Complete the code in following functions:\n",
    "# 1. preprocess()\n",
    "# 2. solution_model()\n",
    "#\n",
    "# Your code will fail to be graded if the following criteria are not met:\n",
    "# 1. The input shape of your model must be (128,128,3), because the testing\n",
    "#    infrastructure expects inputs according to this specification. You must\n",
    "#    resize all the images in the dataset to this size while pre-processing\n",
    "#    the dataset.\n",
    "# 2. The last layer of your model must be a Dense layer with 1 neuron\n",
    "#    activated by sigmoid since this dataset has 2 classes.\n",
    "#\n",
    "# HINT: Your neural network must have a validation accuracy of approximately\n",
    "# 0.95 or above on the normalized validation dataset for top marks.\n",
    "\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# This function downloads and extracts the dataset to the directory that\n",
    "# contains this file.\n",
    "# DO NOT CHANGE THIS CODE\n",
    "# (unless you need to change https to http)\n",
    "def download_and_extract_data():\n",
    "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/satellitehurricaneimages.zip'\n",
    "    urllib.request.urlretrieve(url, 'satellitehurricaneimages.zip')\n",
    "    with zipfile.ZipFile('satellitehurricaneimages.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "# This function normalizes the images.\n",
    "# COMPLETE THE CODE IN THIS FUNCTION\n",
    "def preprocess(image, label):\n",
    "    # NORMALIZE YOUR IMAGES HERE (HINT: Rescale by 1/.255)\n",
    "    image = image / .255\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# This function loads the data, normalizes and resizes the images, splits it into\n",
    "# train and validation sets, defines the model, compiles it and finally\n",
    "# trains the model. The trained model is returned from this function.\n",
    "\n",
    "# COMPLETE THE CODE IN THIS FUNCTION.\n",
    "def solution_model():\n",
    "    # Downloads and extracts the dataset to the directory that\n",
    "    # contains this file.\n",
    "    download_and_extract_data()\n",
    "\n",
    "    IMG_SIZE = 128\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    # The following code reads the training and validation data from their\n",
    "    # respective directories, resizes them into the specified image size\n",
    "    # and splits them into batches. You must fill in the image_size\n",
    "    # argument for both training and validation data.\n",
    "    # HINT: Image size is a tuple\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory='train/',\n",
    "        image_size=(IMG_SIZE,IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory='validation/',\n",
    "        image_size=(IMG_SIZE,IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Normalizes train and validation datasets using the\n",
    "    # preprocess() function.\n",
    "    # Also makes other calls, as evident from the code, to prepare them for\n",
    "    # training.\n",
    "    # Do not batch or resize the images in the dataset here since it's already\n",
    "    # been done previously.\n",
    "    train_ds = train_ds.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
    "        tf.data.experimental.AUTOTUNE)\n",
    "    val_ds = val_ds.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Code to define the model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(50, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Code to compile and train the model\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "          train_ds,\n",
    "          epochs=30,\n",
    "          validation_data = val_ds)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "# Note that you'll need to save your model as a .h5 like this.\n",
    "# When you press the Submit and Test button, your saved .h5 model will\n",
    "# be sent to the testing infrastructure for scoring\n",
    "# and the score will be returned to you.\n",
    "if __name__ == '__main__':\n",
    "    model, history = solution_model()\n",
    "    model.save(\"mymodel.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1627059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
